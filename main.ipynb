{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW2m5Yr9-K6I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "9a28c5cd-1645-4843-98c7-16da0aea0ea8"
      },
      "source": [
        "!pip install pytypo\n",
        "!pip install emoji"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytypo\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/80/b0578690bcac288cf9af76abecf2fd30978ea75ebe67da817c018c444abb/pytypo-0.3.0.tar.gz (74kB)\n",
            "\r\u001b[K     |████▍                           | 10kB 27.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 20kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 30kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 40kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 51kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 61kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 71kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 3.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pytypo\n",
            "  Building wheel for pytypo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytypo: filename=pytypo-0.3.0-cp36-none-any.whl size=72687 sha256=c63effc266a6189f44a9484da0260a53dc91f1ac6437e3226678f4dd0eae0dad\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/81/55/d305159b9e1631c244110dc3b131b1d0dcf041672dd2e8de9a\n",
            "Successfully built pytypo\n",
            "Installing collected packages: pytypo\n",
            "Successfully installed pytypo-0.3.0\n",
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=f8b25a579268e3f8a71df08e690c41b6aab126bfbb8665d48b66302a81fa9606\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "52fhDPLrC-Pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import re\n",
        "import pytypo\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from emoji import UNICODE_EMOJI\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y3tg4voDL1P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "f1f0e685-b4c1-472a-c3a9-3e67d17aa4c9"
      },
      "source": [
        "# Mount gdrive\n",
        "from google.colab import drive, files\n",
        "drive.mount('gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at gdrive; to attempt to forcibly remount, call drive.mount(\"gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "Q9BGgGTxC-Pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify the location of training and test file\n",
        "training_file = 'gdrive/My Drive/shopee/train.csv'\n",
        "test_file = 'gdrive/My Drive/shopee/test.csv'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Q3JTByjnC-Pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load to dataframe\n",
        "training_data = pd.read_csv(training_file)\n",
        "test_data = pd.read_csv(test_file)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XdBdq8TmC-Pp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "377d8304-ea5d-40e7-e9a9-0d005cfece90"
      },
      "source": [
        "# Show some examples of training data\n",
        "training_data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Ga disappointed neat products .. Meletot Hilsn...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Rdtanya replace broken glass, broken chargernya</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Nyesel bngt dsni shopping antecedent photo mes...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Sent a light blue suit goods ga want a refund</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Pendants came with dents and scratches on its ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id                                             review  rating\n",
              "0          0  Ga disappointed neat products .. Meletot Hilsn...       1\n",
              "1          1    Rdtanya replace broken glass, broken chargernya       1\n",
              "2          2  Nyesel bngt dsni shopping antecedent photo mes...       1\n",
              "3          3      Sent a light blue suit goods ga want a refund       1\n",
              "4          4  Pendants came with dents and scratches on its ...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Bg3UYz5nC-Ps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f0e96dd-af25-4e3d-837f-4d9f7ab6fef8"
      },
      "source": [
        "# Show number of samples\n",
        "training_data.shape[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "146811"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "H0VgLvx5C-Pw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "b390b28b-299a-493d-eab3-2c46a90fe5f6"
      },
      "source": [
        "# Show some examples of test data\n",
        "test_data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Great danger, cool, motif and cantik2 jg model...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>One of the shades don't fit well</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Very comfortable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Fast delivery. Product expiry is on Dec 2022. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>it's sooooo cute! i like playing with the glit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id                                             review\n",
              "0          1  Great danger, cool, motif and cantik2 jg model...\n",
              "1          2                   One of the shades don't fit well\n",
              "2          3                                   Very comfortable\n",
              "3          4  Fast delivery. Product expiry is on Dec 2022. ...\n",
              "4          5  it's sooooo cute! i like playing with the glit..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymt3Hm8Tb3_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert rating to score\n",
        "training_data['score'] = training_data.rating.apply(\n",
        "    lambda rating: rating / 5 - 0.1\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q2013VNSqke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check if a character is emoji\n",
        "def is_emoji(char):\n",
        "    return char in UNICODE_EMOJI\n",
        "\n",
        "# Add whitespaces and remove duplicate emoji\n",
        "def preprocess_emoji(text):\n",
        "\n",
        "    # Initialization\n",
        "    result = ''\n",
        "    emoji_list = []\n",
        "    \n",
        "    # Scan the text\n",
        "    for char in text:\n",
        "        if is_emoji(char):\n",
        "            if char not in emoji_list:\n",
        "                result += ' ' + char + ' '\n",
        "                emoji_list.append(char)\n",
        "        else:\n",
        "            result += char\n",
        "    \n",
        "    return(result)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aBDaI9M-ViW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to check elongated word\n",
        "def has_long(sentence):\n",
        "    elong = re.compile(\"([a-zA-Z])\\\\1{2,}\")\n",
        "    return bool(elong.search(sentence))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PndfW-TB-W1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to fix a sentence with elongated word\n",
        "def fix_long(sentence):\n",
        "\n",
        "    # Initialization\n",
        "    result = ''\n",
        "\n",
        "    # Fix the sentence\n",
        "    for word in sentence.split(' '):\n",
        "        if has_long(word):\n",
        "            word = pytypo.correct(word)\n",
        "        result += word + ' '\n",
        "    \n",
        "    return(result)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cboXDD9t-Yby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for text preprocessing\n",
        "def preprocessing(text):\n",
        "    \n",
        "    # Create a space between a word and punctuation\n",
        "    result = preprocess_emoji(text)\n",
        "    result = re.sub(r\"([?.!,¿()-/])\", r\" \\1 \", result)\n",
        "    result = re.sub(r'[\" \"]+', \" \", result)\n",
        "\n",
        "    # Fix elongated word\n",
        "    if has_long(result):\n",
        "        result = fix_long(result)\n",
        "\n",
        "    return(result)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Dy4GOkS1C-QA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c81782c0-1826-4137-a08a-537093b0d9c5"
      },
      "source": [
        "# Get review data\n",
        "reviews = training_data.review.tolist()\n",
        "reviews = [preprocessing(review) for review in reviews]\n",
        "print(reviews[-1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Excellent product quality excellent product price is very good delivery speed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7d0-GPnwC-QD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to tokenize the words\n",
        "def tokenize(texts, num_words=None):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        filters='',\n",
        "        num_words=num_words,\n",
        "        oov_token='<UNK>'\n",
        "    )\n",
        "    tokenizer.fit_on_texts(texts)\n",
        "  \n",
        "    sequences = tokenizer.texts_to_sequences(texts)\n",
        "    sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "        sequences,\n",
        "        padding='post'\n",
        "    )\n",
        "\n",
        "    return sequences, tokenizer"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rJ5-75r_C-QF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize the words\n",
        "sequences, tokenizer = tokenize(reviews, num_words=8000)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DIcW3ogmC-QJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get score data\n",
        "scores = training_data.score.tolist()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Nsj-4aTYC-QL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "x_train, x_validation, y_train, y_validation = train_test_split(\n",
        "    sequences, \n",
        "    scores, \n",
        "    test_size=0.2\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uvnBtWz2C-QO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create tf dataset\n",
        "BUFFER_SIZE = len(x_train)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_set = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_set = train_set.shuffle(BUFFER_SIZE)\n",
        "train_set = train_set.batch(BATCH_SIZE)\n",
        "\n",
        "validation_set = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_validation, y_validation)\n",
        ")\n",
        "validation_set = validation_set.batch(BATCH_SIZE)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qmRm0PEKC-QR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(tokenizer.num_words, 64),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "avM7sEm-C-QV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "  loss=tf.keras.losses.MeanAbsoluteError(),\n",
        "  optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "  metrics=['mean_absolute_error']\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPgvpKWnngwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a callback that saves the model\n",
        "callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='model.h5',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aVcMuIR_C-QX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f98e579-8674-4b65-d6e0-052d78e491a3"
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "  train_set, \n",
        "  epochs=20,\n",
        "  validation_data=validation_set,\n",
        "  callbacks=[callback]\n",
        ")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1836/1836 [==============================] - ETA: 0s - loss: 0.1577 - mean_absolute_error: 0.1577\n",
            "Epoch 00001: val_loss improved from inf to 0.14099, saving model to model.h5\n",
            "1836/1836 [==============================] - 60s 33ms/step - loss: 0.1577 - mean_absolute_error: 0.1577 - val_loss: 0.1410 - val_mean_absolute_error: 0.1410\n",
            "Epoch 2/20\n",
            "1835/1836 [============================>.] - ETA: 0s - loss: 0.1355 - mean_absolute_error: 0.1355\n",
            "Epoch 00002: val_loss improved from 0.14099 to 0.13767, saving model to model.h5\n",
            "1836/1836 [==============================] - 62s 34ms/step - loss: 0.1356 - mean_absolute_error: 0.1356 - val_loss: 0.1377 - val_mean_absolute_error: 0.1377\n",
            "Epoch 3/20\n",
            "1835/1836 [============================>.] - ETA: 0s - loss: 0.1309 - mean_absolute_error: 0.1309\n",
            "Epoch 00003: val_loss improved from 0.13767 to 0.13615, saving model to model.h5\n",
            "1836/1836 [==============================] - 61s 33ms/step - loss: 0.1309 - mean_absolute_error: 0.1309 - val_loss: 0.1361 - val_mean_absolute_error: 0.1361\n",
            "Epoch 4/20\n",
            "1835/1836 [============================>.] - ETA: 0s - loss: 0.1280 - mean_absolute_error: 0.1280\n",
            "Epoch 00004: val_loss improved from 0.13615 to 0.13552, saving model to model.h5\n",
            "1836/1836 [==============================] - 62s 34ms/step - loss: 0.1280 - mean_absolute_error: 0.1280 - val_loss: 0.1355 - val_mean_absolute_error: 0.1355\n",
            "Epoch 5/20\n",
            "1835/1836 [============================>.] - ETA: 0s - loss: 0.1257 - mean_absolute_error: 0.1257\n",
            "Epoch 00005: val_loss improved from 0.13552 to 0.13437, saving model to model.h5\n",
            "1836/1836 [==============================] - 62s 34ms/step - loss: 0.1257 - mean_absolute_error: 0.1257 - val_loss: 0.1344 - val_mean_absolute_error: 0.1344\n",
            "Epoch 6/20\n",
            "1835/1836 [============================>.] - ETA: 0s - loss: 0.1238 - mean_absolute_error: 0.1238\n",
            "Epoch 00006: val_loss improved from 0.13437 to 0.13389, saving model to model.h5\n",
            "1836/1836 [==============================] - 61s 33ms/step - loss: 0.1238 - mean_absolute_error: 0.1238 - val_loss: 0.1339 - val_mean_absolute_error: 0.1339\n",
            "Epoch 7/20\n",
            "1835/1836 [============================>.] - ETA: 0s - loss: 0.1220 - mean_absolute_error: 0.1220\n",
            "Epoch 00007: val_loss did not improve from 0.13389\n",
            "1836/1836 [==============================] - 62s 34ms/step - loss: 0.1220 - mean_absolute_error: 0.1220 - val_loss: 0.1342 - val_mean_absolute_error: 0.1342\n",
            "Epoch 8/20\n",
            "1835/1836 [============================>.] - ETA: 0s - loss: 0.1204 - mean_absolute_error: 0.1204\n",
            "Epoch 00008: val_loss improved from 0.13389 to 0.13241, saving model to model.h5\n",
            "1836/1836 [==============================] - 62s 33ms/step - loss: 0.1204 - mean_absolute_error: 0.1204 - val_loss: 0.1324 - val_mean_absolute_error: 0.1324\n",
            "Epoch 9/20\n",
            "1835/1836 [============================>.] - ETA: 0s - loss: 0.1188 - mean_absolute_error: 0.1188\n",
            "Epoch 00009: val_loss did not improve from 0.13241\n",
            "1836/1836 [==============================] - 62s 34ms/step - loss: 0.1188 - mean_absolute_error: 0.1188 - val_loss: 0.1325 - val_mean_absolute_error: 0.1325\n",
            "Epoch 10/20\n",
            "1835/1836 [============================>.] - ETA: 0s - loss: 0.1172 - mean_absolute_error: 0.1172\n",
            "Epoch 00010: val_loss improved from 0.13241 to 0.13121, saving model to model.h5\n",
            "1836/1836 [==============================] - 62s 34ms/step - loss: 0.1172 - mean_absolute_error: 0.1172 - val_loss: 0.1312 - val_mean_absolute_error: 0.1312\n",
            "Epoch 11/20\n",
            "1835/1836 [============================>.] - ETA: 0s - loss: 0.1158 - mean_absolute_error: 0.1158\n",
            "Epoch 00011: val_loss improved from 0.13121 to 0.13106, saving model to model.h5\n",
            "1836/1836 [==============================] - 62s 34ms/step - loss: 0.1158 - mean_absolute_error: 0.1158 - val_loss: 0.1311 - val_mean_absolute_error: 0.1311\n",
            "Epoch 12/20\n",
            "1835/1836 [============================>.] - ETA: 0s - loss: 0.1145 - mean_absolute_error: 0.1145\n",
            "Epoch 00012: val_loss improved from 0.13106 to 0.13094, saving model to model.h5\n",
            "1836/1836 [==============================] - 62s 34ms/step - loss: 0.1145 - mean_absolute_error: 0.1145 - val_loss: 0.1309 - val_mean_absolute_error: 0.1309\n",
            "Epoch 13/20\n",
            "1835/1836 [============================>.] - ETA: 0s - loss: 0.1131 - mean_absolute_error: 0.1131\n",
            "Epoch 00013: val_loss improved from 0.13094 to 0.13058, saving model to model.h5\n",
            "1836/1836 [==============================] - 64s 35ms/step - loss: 0.1131 - mean_absolute_error: 0.1131 - val_loss: 0.1306 - val_mean_absolute_error: 0.1306\n",
            "Epoch 14/20\n",
            "1835/1836 [============================>.] - ETA: 0s - loss: 0.1120 - mean_absolute_error: 0.1120\n",
            "Epoch 00014: val_loss did not improve from 0.13058\n",
            "1836/1836 [==============================] - 64s 35ms/step - loss: 0.1120 - mean_absolute_error: 0.1120 - val_loss: 0.1307 - val_mean_absolute_error: 0.1307\n",
            "Epoch 15/20\n",
            "1835/1836 [============================>.] - ETA: 0s - loss: 0.1109 - mean_absolute_error: 0.1109\n",
            "Epoch 00015: val_loss improved from 0.13058 to 0.13023, saving model to model.h5\n",
            "1836/1836 [==============================] - 64s 35ms/step - loss: 0.1109 - mean_absolute_error: 0.1109 - val_loss: 0.1302 - val_mean_absolute_error: 0.1302\n",
            "Epoch 16/20\n",
            "1835/1836 [============================>.] - ETA: 0s - loss: 0.1096 - mean_absolute_error: 0.1096\n",
            "Epoch 00016: val_loss did not improve from 0.13023\n",
            "1836/1836 [==============================] - 63s 35ms/step - loss: 0.1096 - mean_absolute_error: 0.1096 - val_loss: 0.1302 - val_mean_absolute_error: 0.1302\n",
            "Epoch 17/20\n",
            "1835/1836 [============================>.] - ETA: 0s - loss: 0.1086 - mean_absolute_error: 0.1086\n",
            "Epoch 00017: val_loss did not improve from 0.13023\n",
            "1836/1836 [==============================] - 64s 35ms/step - loss: 0.1086 - mean_absolute_error: 0.1086 - val_loss: 0.1308 - val_mean_absolute_error: 0.1308\n",
            "Epoch 18/20\n",
            "1835/1836 [============================>.] - ETA: 0s - loss: 0.1078 - mean_absolute_error: 0.1078\n",
            "Epoch 00018: val_loss did not improve from 0.13023\n",
            "1836/1836 [==============================] - 64s 35ms/step - loss: 0.1078 - mean_absolute_error: 0.1078 - val_loss: 0.1306 - val_mean_absolute_error: 0.1306\n",
            "Epoch 19/20\n",
            "1835/1836 [============================>.] - ETA: 0s - loss: 0.1068 - mean_absolute_error: 0.1068\n",
            "Epoch 00019: val_loss did not improve from 0.13023\n",
            "1836/1836 [==============================] - 64s 35ms/step - loss: 0.1068 - mean_absolute_error: 0.1068 - val_loss: 0.1303 - val_mean_absolute_error: 0.1303\n",
            "Epoch 20/20\n",
            "1835/1836 [============================>.] - ETA: 0s - loss: 0.1059 - mean_absolute_error: 0.1059\n",
            "Epoch 00020: val_loss improved from 0.13023 to 0.12999, saving model to model.h5\n",
            "1836/1836 [==============================] - 64s 35ms/step - loss: 0.1059 - mean_absolute_error: 0.1059 - val_loss: 0.1300 - val_mean_absolute_error: 0.1300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBf5PNACn_YQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0cbc6190-6f12-4579-e23a-a48aeab5a0af"
      },
      "source": [
        "# Load the best model\n",
        "model = tf.keras.models.load_model('model.h5')\n",
        "model.evaluate(validation_set)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "459/459 [==============================] - 6s 13ms/step - loss: 0.1300 - mean_absolute_error: 0.1300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12998637557029724, 0.12998637557029724]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjjkSIbjYW1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make prediction\n",
        "score_prediction = model.predict(x_validation)\n",
        "score_prediction = score_prediction.flatten().tolist()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFWqzyI9PaYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to convert score to rating\n",
        "def score_to_rating(input_list):\n",
        "    \n",
        "    result = []\n",
        "    for score in input_list:\n",
        "        if score < 0.2:\n",
        "            result.append(1)\n",
        "        elif 0.2 <= score < 0.4:\n",
        "            result.append(2)\n",
        "        elif 0.4 <= score < 0.6:\n",
        "            result.append(3)\n",
        "        elif 0.6 <= score < 0.8:\n",
        "            result.append(4)\n",
        "        else:\n",
        "            result.append(5)\n",
        "    \n",
        "    return(result)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VufKi1xcQGw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert score to rating\n",
        "rating_prediction = score_to_rating(score_prediction)\n",
        "rating_actual = score_to_rating(y_validation)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XT4YVUxMjou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63109b95-a79d-493d-8256-02acb7a225b9"
      },
      "source": [
        "# Show accuracy \n",
        "accuracy_score(rating_actual, rating_prediction)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.46395123114123216"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fgtu8KapAfE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "fc8cefbd-b1ef-4610-ba75-34c92d6de9d6"
      },
      "source": [
        "# Get test data\n",
        "test_reviews = test_data.review.tolist()\n",
        "test_reviews = [preprocessing(review) for review in test_reviews]\n",
        "test_sequences = tokenizer.texts_to_sequences(test_reviews)\n",
        "test_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    test_sequences,\n",
        "    padding='post',\n",
        "    maxlen=sequences.shape[1]\n",
        ")\n",
        "print(test_reviews[-1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rapid response and detail . . . \n",
            "Thanks gan , the goods have been received well n packing a secure . . . . \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd7D1AYtoOKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict the test data\n",
        "prediction = model.predict(test_sequences)\n",
        "prediction = prediction.flatten().tolist()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCmPY_2UX8iw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert score to rating\n",
        "prediction = score_to_rating(prediction)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5GsZFa2rUyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add prediction to dataframe\n",
        "test_data['rating'] = prediction"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFgIg7oAsC1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Export to a csv file\n",
        "test_data.loc[:, ['review_id', 'rating']].to_csv(\n",
        "    'submission.csv', index=False, header=True\n",
        ")"
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}
